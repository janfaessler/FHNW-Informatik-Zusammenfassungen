\documentclass[a4paper, 11pt]{article} % ISO-8859-1 - latin1

%Math
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{ulem}
\usepackage{stmaryrd} %f\UTF{00FC}r Blitz!

%PageStyle
\usepackage[ngerman]{babel} % deutsche Silbentrennung
\usepackage[ansinew]{inputenc} % wegen deutschen Umlauten
\usepackage{fontenc}
\usepackage{fancyhdr, graphicx} %for header/footer
\usepackage{wasysym}
\usepackage{fullpage}
\usepackage{textcomp}
\usepackage{floatflt}

% Listings
\usepackage{color}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{caption}

% Commands
\newcommand{\Bold}[1]{\textbf{#1}} %Boldface
\newcommand{\Kursiv}[1]{\textit{#1}} %Italic
\newcommand{\T}[1]{\text{#1}} %Textmode
\newcommand{\Nicht}[1]{\T{\sout{$ #1 $}}} %Streicht Shit durch
\newcommand{\lra}{\leftrightarrow} %Arrows
\newcommand{\ra}{\rightarrow}
\newcommand{\la}{\leftarrow}
\newcommand{\lral}{\longleftrightarrow}
\newcommand{\ral}{\longrightarrow}
\newcommand{\lal}{\longleftarrow}
\newcommand{\Lra}{\Leftrightarrow}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\La}{\Leftarrow}
\newcommand{\Lral}{\Longleftrightarrow}
\newcommand{\Ral}{\Longrightarrow}
\newcommand{\Lal}{\Longleftarrow}

% Code listenings
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
 
\lstdefinestyle{JavaStyle}{
 language=Java,
 basicstyle=\footnotesize\ttfamily, % Standardschrift
 numbers=left,               % Ort der Zeilennummern
 numberstyle=\tiny,          % Stil der Zeilennummern
 stepnumber=5,              % Abstand zwischen den Zeilennummern
 numbersep=5pt,              % Abstand der Nummern zum Text
 tabsize=2,                  % Groesse von Tabs
 extendedchars=true,         %
 breaklines=true,            % Zeilen werden Umgebrochen
 frame=b,         
 %commentstyle=\itshape\color{LightLime}, Was isch das? O_o
 %keywordstyle=\bfseries\color{DarkPurple}, und das O_o
 basicstyle=\footnotesize\ttfamily,
 stringstyle=\color[RGB]{42,0,255}\ttfamily, % Farbe der String
 keywordstyle=\color[RGB]{127,0,85}\ttfamily, % Farbe der Keywords
 commentstyle=\color[RGB]{63,127,95}\ttfamily, % Farbe des Kommentars
 showspaces=false,           % Leerzeichen anzeigen ?
 showtabs=false,             % Tabs anzeigen ?
 xleftmargin=17pt,
 framexleftmargin=17pt,
 framexrightmargin=5pt,
 framexbottommargin=4pt,
 showstringspaces=false      % Leerzeichen in Strings anzeigen ?        
}

%Config
\renewcommand{\headrulewidth}{0pt}
\setlength{\headheight}{15.2pt}
\pagestyle{plain}

%Metadata
\title{Algorithmen \& Datenstrukturen 2}
\author{Jan Fässler}
\date{3. Semester (HS 2012)}
\fancyfoot[C]{If you use this documentation for a exam, you should offer a beer to the authors!}

% hier beginnt das Dokument
\begin{document}

% Titelbild
\maketitle
\thispagestyle{fancy}

\newpage

% Inhaltsverzeichnis
\pagenumbering{Roman}
\tableofcontents	  	


\newpage
\setcounter{page}{1}
\pagenumbering{arabic}

% Inhalt Start

\section{Listen}
Eine verkettete Liste (linked list) ist eine dynamische Datenstruktur zur Speicherung von Objekten. Sie eignen sich für das speichern einer unbekannten Anzahl von Objekten, sofern kein direkter Zugriff auf die einzelnen Objekte benötigt wird. Jedes Element in einer Liste muss neben den Nutzinformationen auch die notwendigen Referenzen zur Verkettung enthalten.\\ 
Es gibt drei verschiedene Arten von Listen:\\
\begin{center}
\includegraphics[scale=0.4]{listen.png}
\end{center}

\lstinputlisting[language=java,caption=einfache Linked List,style=JavaStyle]{linked_list.java}


\subsection{Stack}
Der Stack ist eine dynamische Datanstruktur bei der man nur auf das oberste Element des Stabels zugreifen (top), ein neues Element auf den Stabel legen (push) oder das oberste Element des Stapels entfernen (pop) kann.
\lstinputlisting[language=java,caption=Implementierung eines Stacks,style=JavaStyle]{stack.java}

\subsection{Erweiterte Liste}
Dies ist mal eine mögliche und vor allem nur teilweise Implementierung einer doppelt verlinkten Liste. Die Implementierung des Iterators und der sortierung sind ausgeklammert in Unterkapitel.
\lstinputlisting[language=java,caption=Liste mit Iterator,style=JavaStyle]{advanced_list.java}

\subsubsection{Iterators}
Die Schnittstelle java.util.Iterator, erlaubt das Iterieren von Containerklassen. Jeder Iterator stellt Funktionen namens next(), hasNext() sowie eine optionale Funktion namens remove() zur Verfügung. Der folgende ListIterator stellt auch noch Funktionen für rückwertsiterieren zur Verfügung, sowie die Möglichkeit den aktuellen Index abzufragen. Zudem kann damit noch direkt über den Iterator Elemente eingefügt oder ersetzt werden.

\lstinputlisting[language=java,caption=Iterators,style=JavaStyle]{linked_list_iterators.java}

\subsubsection{Merge Sort}
\lstinputlisting[language=java,caption=Merge Sort,style=JavaStyle]{linked_list_mergesort.java}

\subsection{Skip-Liste}
Die Skip-Liste ist eine sortierte, einfach verkettete Liste, die uns aber ein schnelleres Suchen von Elementen in der Datenstruktur erlaubt. In einer sortierten, verketteten Liste müssen wir jedes Element einzeln durchlaufen bis wir das gewünschten Element gefunden haben. Wenn wir nun aber in der sortierten Liste auf jedem zweiten Element eine zusätzliche Referenz auf zwei Elemente weiter hinten setzen, dann reduziert sich die Anzahl zu besuchender Elemente auf einen Schlag um rund die Hälfte. Genau betrachtet müssen wir nie mehr als $(n/2) + 1$ Elemente besuchen (n ist die Länge der Liste). 
\begin{center}
\includegraphics[scale=0.65]{skip_liste.png}
\end{center}

\subsubsection{Beispiel}
\lstinputlisting[language=java,caption=Skip List,style=JavaStyle]{skip_liste.java}

\newpage
\section{Bäume}
Bäume sind verallgemeinerte Listenstrukturen. Ein Element, üblicherweise spricht man von Knoten (node), hat nicht, wie im Falle linearer Listen, nur einen Nachfolger, sondern eine endliche, begrenzte Anzahl von Söhnen. In der Regel ist einer der Knoten als Wurzel (root) des Baumes ausgeprägt. Das ist zugleich der einzige Knoten ohne Vorgänger. Jeder andere Knoten hat einen (unmittelbaren) Vorgänger, der auch Vater des Knotens genannt wird. Eine Folge $p_0$, ..., $p_k$ von Knoten eines Baumes, die die Bedingung erfüllt, dass $p_i+1$ Sohn von $p_i$ ist für $0 \leq i <$ k, heisst Pfad (path) mit Länge k, der $p_0$ mit $p_k$ verbindet. Jeder von der Wurzel verschiedene Knoten eines Baumes ist durch genau einen Pfad mit der Wurzel verbunden.
\begin{center}
\includegraphics[scale=0.65]{tree.png}
\end{center}

\subsection{Binäre Suchbäume}
Ein binärer Suchbaum ist ein geordneter Baum mit Ordnung d = 2. In jedem Knoten wird ein Suchschlüssel so abgespeichert, dass alle Suchschlüssel des linken Teilbaums des Knotens kleiner und alle Suchschlüssel des rechten Teilbaums des Knotens grösser sind. Das heisst, dass an jedem Knoten alle kleineren Suchschlüssel über den linken Sohn und alle grösseren Suchschlüssel über den rechten Sohn erreicht werden.\\
Die so geordneten Knoten in einem balancierten binären Suchbaum erlauben ein schnelles Suchen. Der maximale Suchaufwand hängt direkt von der Höhe des Baumes ab und wächst nur logarithmisch mit der Anzahl der Knoten im Baum.
	
\subsubsection{Traversieren}
Das Durchlaufen kann auf mindestens drei verschiedene Arten erfolgen: Preorder, Inorder, Postorder.
\begin{description}
	\item[Inorder] \hfill \\
		1. traversiere den linken Teilbaum des Knotens v; 2. besuche den Knoten v; 3. traversiere den rechten Teilbaum des Knotens v.
	\item[Preorder] \hfill \\
		Bei Preorder wird zuerst Knoten v besucht, dann erst 99 der linke Teilbaum von v in Preorder und anschliessend noch der rechte Teilbaum von v in Preorder durchlaufen.
	\item[Postorder] \hfill \\
		Hier wird zuerst der linke Teilbaum von v, dann der rechte Teilbaum von v und erst zum Schluss der Knoten v besucht.
\end{description}

\subsection{Balancierte Bäume}
Ein binärer Suchbaum ist AVL-ausgeglichen oder höhenbalanciert oder eben ein AVL- Baum, wenn für jeden Knoten v des Baumes gilt, dass sich die Höhe des linken Teilbaumes von der Höhe des rechten Teilbaumes von v höchstens um eins unterscheidet. \\

\subsubsection{Berechnungen}

h := Höhe = Maximal auftretende Tiefe\\
$bal(t) := h(t_r) - h(t_l) ~// \in [-1,0,1] \Ra $ AVL-Baum\\

\subsubsection{Einfügen}
\Bold{Fall 1: p hat 1 Sohn}, einfügen an der leeren Stelle: \\
einf. Links: $bal(p) =+ 1 \rightarrow bal(p) = 0$\\
einf. Rechts: $bal(p) =- 1 \rightarrow bal(p) = 0$ \\
Höhe des Sohnes: $h(p) = const$ / Balance des Vater: $bal(v) = const$ \\
$\Ra$ \Bold{fertig} \\
\\
\Bold{Fall 2: p hat keine Söhne}, einfügen links/rechts \\
einf. links/rechts:$ bal(p) =\pm 1$ \\
Schieflage: ++$h(p)$ 
\begin{description}
	\item[Variante a.)] \hfill \\
		$bal(v) \neq 0$ / p ist kürzerer Ast $\Ra bal(v)=0$ \\
		\& $h(v)=const$ $\Ra$ \Bold{fertig}
	\item[Variante b.)] \hfill \\
		$bal(v) = 0$ $\Ra bal(v)=\pm1$ \\
		\& ++$h(v)$ $\Ra$ \Bold{weiter testen mit Vater/Opa/...}
	\item[Variante c.)] \hfill \\
		$bal(v) \neq 0$ \& p ist längerer Ast \\
		$\Ra bal(v)=\pm2! \Ra$ \Bold{es muss balaciert werden:} \\
\end{description}
\begin{tabular}{|l|l|}
	\hline 
	$sgn(bal(v))=sgn(bal(p))$ & $sgn(bal(v)) \neq sgn(bal(p))$ \\
	\hline 
	& \\
	\includegraphics[scale=0.5]{rotation_right.png} & \includegraphics[scale=0.45]{rotation_left_right.png} \\
	\hline
\end{tabular}

\subsubsection{Löschen}
Bei einem nicht ALV Baum ist der Aufwand für das löschen eines Elementes überschaubar:
\begin{description}
	\item[I) p hat keinen Sohn] \hfill \\
		p entfernen
	\item[II) p hat einen Sohn] \hfill \\
		p entfernen und Sohn nachziehen
	\item[III) p hat zwei Söhne] \hfill \\
		p entfernen, durch nächstkleineres oder nächstgrösseres Element ersetzen \\
		(dies kann eventuell zu einer weiteren Löschoperation vom Typ II weiter unten führen)
\end{description}
Bei einem ALV Baum muss nach dem löschen noch balanciert werden.

\subsubsection{Beispiel}
\lstinputlisting[language=java,caption=Insert \& Delete from a AVL Tree,style=JavaStyle]{avl-operations.java}

\subsection{Heaps / Priority-Queues}
Die wichtigsten Operationen bei Warteschlangen (queues) sind der Zugriff auf das vorderste Objekt, das Einfügen eines Objektes am Ende der Warteschlange und das Entfernen des vordersten Objektes. Solche einfache Warteschlangen werden üblicherweise mit verketteten Listen realisiert. \\
Die wichtigsten Operationen von Prioritätswarteschlangen unterscheiden sich leicht von denjenigen der einfachen Warteschlangen. Der Zugriff auf das vorderste Objekt wird durch den Zugriff auf ein Objekt mit höchster Priorität ersetzt. Entsprechend wird das Entfernen des vordersten Objektes durch das Entfernen eines Objektes mit höchster Priorität ersetzt. Schliesslich wird ein neues Objekt nicht einfach am Ende eingefügt, sondern es muss an der richtigen Position gemäss seiner Priorität eingereiht werden. Dabei muss die richtige Position aber zuerst gesucht werden.

\subsubsection{Bedingungen}
Man unterscheidet Heaps in Min-Heaps und Max-Heaps. Bei Min-Heaps bezeichnet man die Eigenschaft, dass die Schlüssel der Kinder eines Knotens stets größer als der Schlüssel ihres Vaters sind, als Heap-Bedingung. Dies bewirkt, dass an der Wurzel des Baumes stets ein Element mit minimalem Schlüssel im Baum zu finden ist. Umgekehrt verlangt die Heap-Bedingung bei Max-Heaps, dass die Schlüssel der Kinder eines Knotens stets kleiner als die ihres Vaters sind. Hier befindet sich an der Wurzel des Baumes immer ein Element mit maximalem Schlüssel.

\subsubsection{Element mit höchster Priorität entfernen}
Das eigentliche Entfernen eines Objektes mit höchster Priorität entspricht dem Entfernen der Wurzel des Heaps.Dies hinterlässt im Allgemeinen zwei separate Heaps, nämlich den linken und den rechten Teilbaum der Wurzel. Die beiden Heaps werden zusammengeführt in dem der Knoten genommen wird, der auf dem untersten Niveau am weitesten rechts steht, und an der Stelle der Wurzel eingefügt wird. \\
Dadurch wird aber in der Regel die Heap Bedingungen verletzt. Um dies zu korrigieren lässt man die neue Wurzel versickern (\textbf{shift-down}) bis die Bedingungen wieder korrekt sind. Dabei bedeutet ein einzelner Versickerungsschritt das Vertauschen des Schlüssels eines inneren Knotens mit dem grösseren Schlüssel seiner beiden Söhne. \\
Der Aufwand des Versickerns hängt direkt von der Länge des Pfades und somit von der Höhe des Heap ab. Da die Höhe eines balancierten Binärbaumes logarithmisch in der Anzahl der Knoten \textit{(= n)} ist, resultiert gesamthaft eine logarithmische Zeitkomplexität für das Entfernen eines Schlüssels mit höchster Priorität: \textit{O(log n)}.

\subsubsection{Einfügen eines Objektes mit gegebener Priorität}
Das neue Objekt wird am letzten Knoten im Heap eingefügt. Dazu werden alle Knoten im Heap fortlaufend nummerriert. Beginnend bei der Wurzel mit 1, dann alle weiteren Niveaus der Reihe nach und innerhalb der Niveaus von links nach rechts. Auch hier ist es sehr warscheinlich, dass die Heap Bedinungen verletzt werden. Man wenden hier das genau gegenteilige Verfahren an (\textbf{shift-up}): \\
Erfüllt Knoten v die Heap-Bedingung nicht, so wird v mit demjenigen Sohn von v, welcher den grösseren Schlüssel besitzt, vertauscht.

\subsubsection{Entfernen eines Objektes an beliebiger, aber gegebener Position}
Auch bei dieser Operation wird die Nummerierung der Knoten benötigt. Falls der zu entfernende Knoten der letzte Knoten im Heap ist, kann dieser entfernt werden ohne die Heap Bedinungen zu verletzen. Andernfalls wird der zu löschende Knoten v mit dem letzten Knoten p des heaps vertauscht, damit v problemlos gelöscht werden kann. \\
m Allgemeinen wird durch das Vertauschen der beiden Knoten v und p die Heap-Bedingung verletzt, entweder hat p einen grösseren Schlüssel als sein neuer Vater oder p hat einen kleineren Schlüssel als einer seiner neuen Söhne. Im ersteren Fall wird auf dem Pfad von p zur Wurzel die \textbf{sift-up}-Operation angewandt und im letzteren Fall lassen wir p mittels \textbf{sift-down}-Operation versickern.

\subsubsection{Aufbau eines Heaps}
Mit den n Schlüsselwerten bauen wir zuerst einen balancierten Binärbaum auf, so dass alle Blätter auf höchstens zwei verschiedenen Niveaus auftreten und dass auf demjenigen Niveau, wo sowohl innere Knoten als auch Blätter auftreten können, kein innerer Knoten weiter rechts liegt als irgend ein Blatt. Im Allgemeinen wird jedoch die Heap-Bedingung dadurch nicht erfüllt. \\
Bevor wir auf die Umstrukturierung eingehen, zeigen wir den balancierten Binärbaum, welcher aus der Schlüsselmenge { 7, 5, 3, 11, 14, 8, 20, 17 } anfänglich aufgebaut wird. Die Anzahl innerer Knoten ist n = 8.
\begin{center}
\includegraphics[scale=0.4]{heap-unsortiert.png}
\end{center}
Für jeden inneren Knoten, dessen beide Söhne beides Blätter sind, gilt trivialerweise, dass die Heap- Bedingung bereits erfüllt ist. Dies ist der Fall für alle Knoten mit einer Nummer grösser als $(n/2)$. Im oben stehenden Beispiel sind dies die Knoten 5 bis 8. Die restlichen Knoten mit den Nummern 1 bis $(n/2)$ werden nun in der Reihenfolge $(n/2)$, $(n/2)-1$, ..., 1 mit der Operation \textbf{sift-down} versickert. Für oben stehendes Beispiel ergeben sich dadurch die folgenden Veränderungen und schliesslich der unten stehende Heap:\\ \\
- Knoten 4 mit Schlüssel 11 versickern: 7, 5, 3, 17, 14, 8, 20, 11\\
- Knoten 3 mit Schlüssel 3 versickern: 7, 5, 20, 17, 14, 8, 3, 11\\
- Knoten 2 mit Schlüssel 5 versickern: 7, 17, 20, 11, 14, 8, 3, 5\\
- Knoten 1 mit Schlüssel 7 versickern: 20, 17, 8, 11, 14, 7, 3, 5\\
\begin{center}
\includegraphics[scale=0.4]{heap-sortiert.png}
\end{center}

\subsubsection{Sortierung}
\lstinputlisting[language=java,caption=Sortierung,style=JavaStyle]{HeapSort.java}


\pagebreak
\section{Hash-Verfahren}
Die grosse Aufgabe bei Datenstrukturen sind die drei Operationen Einfügen, Suchen und Entfernen möglichst schnell anzubieten. Das schnellste bisher sind die AVL-Bäume, die alle drei Operationen in $O(log(n))$ anbieten. Im Gegensatz dazu steht das Array, welches alle drei Operationen in $O(1)$ anbietet. Es kann direkt auf einzelne Speicherzellen zugegriffen werden ohne umständliches Vergleichen und/oder Suchen. Arrays sind aber nicht dynamisch und es ist nicht möglich, ein unendlich langes Array zu haben, sondern es muss auf eine fixe Grösse limitiert werden. Die Hash-Datenstruktuen versuchen das schnelle Array mit der Unlimitiertheit der dynamischen Datenstrukturen zu verbinden.

\subsection{Begriffe}
\begin{description}
	\item[Quellmenge] \hfill \\ Die Menge aller Möglicher Nachrichten.
	\item[Zielmenge] \hfill \\ Menge aller möglichen Hash-Werten. Sie ist im Allgemeinen viel kleiner als die Quellmenge.
	\item[Kollision] \hfill \\ Nachrichten welche den selben Hash-Wert haben.
	\item[Hash-Funktion] \hfill \\ Enthält die Berechnung, die es erlaubt, von einer beliebigen Nachricht einen Hash-Wert fixer Länge zu berechnen.
\end{description}

\subsection{Hash-Funktionen}
\begin{description}
	\item[Divisions-Rest-Methode] \hfill \\
	Ein nahe liegendes Verfahren zur Erzeugung eines Hash-Wertes ist es, den Rest einer ganzzahligen  Division von k durch m zu nehmen: $h(k) = k$ $mod$ $m$. \\
	Für die Qualität dieser Hash-Funktion ist dann allerdings eine geschickte Wahl von m entscheidend. Eine gute Wahl ist eine Primzahl welche kein Teiler einer zweierpotenz ist.
	\item[Multiplikative Methode] \hfill \\
	Der gegebene Schlüssel wird mit einer irrationalen Zahl multipliziert; der ganzzahlige Anteil des Resultats wird abgeschnitten. Auf diese Weise erhält man für verschiedene Schlüssel verschiedene Werte zwischen 0 und 1. Für Schlüssel 1, 2, 3, ..., n sind diese Werte ziemlich gleichmässig im Intervall [0, 1] verstreut.
\begin{center}
$h(k) = \lfloor (kA\mod 1) \times m \rfloor = \lfloor  (k A - \lfloor k A \rfloor) \times m \rfloor,\quad 0<A<1,\quad  m = $ Anz. Adressen
\end{center} 
\end{description}
Jede Hash-Funktion aus H bildet alle denkbar möglichen Schlüsselwerte auf einen Index aus \{0, 1, ..., m-1\} ab. H heisst nun \textbf{universell}, wenn für je zwei verschiedene Schlüsselwerte x und y gilt:
\begin{center}
$\frac{|[h \in H : h(x)=h(y)]|}{|H|} <= \frac{1}{m}$
\end{center} 
H ist also dann universell, wenn für jedes Paar von verschiedenen Schlüsseln höchstens der m-te Teil der Hash-Funktionen aus H zu einer Indexkollision für dieses Schlüsselpaar führen.

\subsection{Verkettung der Überläufer}
Das zu lösende Problem sind die Synonyme. Soll in ein Array, das bereits den Schlüssel k enthält, ein Synonym k' von k eingefügt werden, so ergibt sich eine Indexkollision. Der Platz h(k) = h(k') ist bereits besetzt und k', ein Überläufer, muss anderswo gespeichert werden. Eine einfache Art, Überläufer zu speichern, ist die, sie ausserhalb des Arrays abzulegen, und zwar in dynamisch veränderbaren Strukturen. So kann man etwa die Überläufer zu jedem Array-Index in einer linearen Liste verketten; diese Liste wird an den Array-Eintrag angehängt, der sich durch Anwendung der Hash-Funktion auf die Schlüssel ergibt.

\subsubsection{Separate Verkettung}
Bei der separaten Verkettung der Überläufer ist jedes Element der Hash-Tabelle das Anfangselement einer Überlaufkette (verkettete lineare Liste). Angenommen wir hätten eine Klasse List mit einer inneren Klasse List.Element. Somit können wir ein Array von solchen Elementen als unsere Hash-Tabelle verwenden. 
\begin{center}
\includegraphics[scale=0.4]{hash-separate-verkettung.png}
\end{center}

\subsubsection{Direkte Verkettung}
Bei der direkten Verkettung der Überläufer ist jedes Element der Hash-Tabelle eine eigenständige Liste. In der Hash-Tabelle werden also bloss Referenzen auf Listen gespeichert und die Datensätze in die Listen eingefügt. 
\begin{center}
\includegraphics[scale=0.4]{hash-direkte-verkettung.png}
\end{center}

\subsection{Offene Hash-Verfahren}
Mit der Idee von offenen Hash-Verfahren wird ein Ansatz verfolgt, die Überläufer innerhalb der Hash-Tabelle unterzubringen. Wenn also beim Versuch den Schlüssel k in die Hash- Tabelle an Position h(k) einzutragen festgestellt wird, dass t[h(k)] bereits belegt ist, so muss man nach einer festen Regel einen anderen, nicht belegten Platz finden, an dem man k unterbringen kann. Da man von vornherein nicht weiss, welche Plätze belegt sein werden und welche nicht, definiert man für jeden Schlüssel eine Reihenfolge, in der alle Speicherplätze einer nach dem anderen betrachtet werden. Sobald dann ein betrachteter Platz frei ist, wird der Datensatz dort gespeichert. Die Magie liegt also darin, wie man abhängig vom jeweiligen Schlüssel, die Hash-Tabelle inspiziert. Diese Reihenfolge nennt sich Sondierungsfolge. \\
Um einen Schlüssel zu löschen ohne die Sondierungsreienfolge zu zerstören benötigt es einen kleinen Trick. Er wird nicht wirklich entfernt, sondern lediglich als entfernt markiert. Wird ein neuer Schlüssel eingefügt, so wird der Platz von k als frei angesehen; wird ein Schlüssel gesucht, so wird der Platz von k als belegt angesehen.

\subsubsection{Schema}
Sei s(j,k) eine Funktion von j und k so, dass $(h(k)-s(j,k))$ $mod$ $m$ für j = 0, 1, ..., m-1 eine Sondierungsfolge bildet, d.h. eine Permutation aller Hash-Adressen. Es sei stets noch mindestens ein Platz in der Hash-Tabelle frei.

\subsubsection{Lineares Sondieren}
Beim linearen Sondieren ergibt sich für den Schlüssel k die Sondierungsfolge \\
$h(k), h(k)-1, h(k)-2, h(k)-3, ..., 0, m-1, m-2, m-3, ..., h(k) + 1$ \\
Es wird einfach immer ein Array-Index kleiner versucht, bis der kleinste Index erreicht wird (also 0) und dann wird einfach vom höchsten Index an weiter gesucht. \\
Das Schema ist beim linearen Sondieren die Funktion $s(j,k) = j$.

\subsubsection{Double-Hashing}
Für die Sondierungsfolge wird eine zweite Hash-Funktion verwendet. Die gewählte Sondierungsfolge für Schlüssel k ist \\
$h(k), h(k)-h'(k), h(k)-2*h'(k), ..., h(k)-(m-1)*h'(k)$ \\
wenn h'(k) die zweite Hash-Funktion bezeichnet. Damit wir keine Indizes errechnen, die kleiner 0 sind,
wird das Resultat jeweils noch modulo m gerechnet.

\subsubsection{Implementierung}
\lstinputlisting[language=java,caption=Abstrakte Klasse,style=JavaStyle]{OpenHashMap.java}

\lstinputlisting[language=java,caption=Besipiel,style=JavaStyle]{LinearHashMap.java}

\pagebreak
\section{Graphen}
\subsection{Definitionen}
\begin{description}
	\item[Graph] \hfill \\
		Ein Graph besteht aus einer Knotenmenge V (vertices) und einer Kantenmenge E (edges). \\
		Dabei gilt:
		\begin{itemize}
			\item[i] $|V|=n>0$
			\item[ii] $E=\{(u,v)|u,v \in V\}$ wobei u und v nicht verschieden sein müssen. Eine Kante ist also ein Paar von Knoten. Falls $u=v$ gilt, dann sprechen wir von einer Schleife oder Schlinge, also einer Kante, welche einen Knoten mit sich selber verbindet. \\
			$|E| = m \geq 0$
		\end{itemize}
	\item[Notation] \hfill \\
		$V = \{1, 2, ..., n\}$ und $E = \{(1,2), (3,2), ..., (2,4)\}$
	\item[Knoten] \hfill \\
		Der Grad eines Knoten in einem Graphen entspricht der Menge der Kanten, welche den Knoten als (einen) Anfangs- bzw. Endpunkt haben. Der Grad wird angegeben als \textbf{deg(v)}. Eine Kante ist zu ihren Anfangs- und Endknoten \textbf{inzident}. Alle Knoten, mit denen ein Knoten durch eine Kante verbunden ist, heissen \textbf{adjazente} Knoten. Diese adjazenten Knoten werden meist auch als Nachbarn bezeichnet.
	\item[Kanten] \hfill \\
		Eine Kante verbindet zwei Knoten miteinander. Dabei kann sie eine Richtung haben (\textbf{gerichtet}), oder aber auch \textbf{ungerichtet} sein. Wenn sie eine Richtung hat, wird sie als Pfeil gezeichnet und als Paar von Knoten (u, v) symbolisiert, wobei u der Startknoten und v der Zielknoten ist. Eine ungerichtete Kante wird als Verbindungslinie gezeichnet und als Menge {u, v} symbolisiert. \\
		Neben der Richtung kann eine Kante auch noch ein Gewicht haben. Solche Kanten heissen \textbf{gewichtete} Kanten. Gewichte stellen zum Beispiel die Entfernung zweier Knoten oder die Bandbreite einer Internetleitung dar.\\
		Sind zwei Knoten durch mehrere direkte Kanten verbunden, wird diese Gruppe als Mehrfachkante zusammengefasst.\\
		Ist ein Knoten mit sich selber durch eine Kante verbunden, wird diese Kante als Schlinge bezeich- net. (Für den Grad eines Knoten wird diese Kante zweimal gezählt.)
	\item[Zusammenhängende Graphen] \hfill \\
		Ein Graph ist zusammenhängend, wenn von jedem Knoten jeder andere Knoten über Kanten erreicht werden kann. Ist ein Graph nicht zusammenhängend, besteht er aus mehreren Komponenten. Das Tramnetz einer Stadt ist üblicherweise ein zusammenhängender Graph. Alle Tramnetze der Schweiz gemeinsam betrachtet, sind jedoch ein nicht zusammenhängender Graph.
		\begin{center}
			\includegraphics[scale=0.4]{graphen-zusammenhaengend.png}
		\end{center}
	\item[Baum] \hfill \\
		Ein Baum ist ein spezieller zusammenhängender Graph. Er zeichnet sich dadurch aus, dass er keine Kreise und somit auch keine Schlingen enthält (siehe Unterkapitel Kreise).
\end{description}

\subsection{Einfache Graphen}
Ein einfacher Graph ist ein ungerichteter Graph ohne Mehrfachkanten und ohne Schlingen. Dabei gilt:
\begin{itemize}
	\item Die Summe aller Knotengrade ist gerade (Zweifachen der Anzahl Kanten m).
	\item Die Anzahl der Knoten mit ungeradem Knotengrad ist gerade.
\end{itemize}

\subsubsection{Vollständige Graphen}
Ein vollständiger Graph ist ein einfacher Graph. Er hat aber die zusätzliche Eigenschaft, dass von jedem Knoten aus alle andern Knoten direkt mit einer Kante verbunden sind. Solche Graphen können für die Darstellung eines Tourniers verwendet werden, bei dem jedes Team gegen jedes andere Team spielen muss.
\begin{center}
\includegraphics[scale=0.4]{graphen-vollstaendig.png}
\end{center}

\subsubsection{Kreise}
Ein Kreis ist ein einfacher Graph, bei dem alle Knoten den Grad 2 haben. Von jedem Knoten kommt man auf zwei Wegen zu jedem anderen Knoten.
\begin{center}
\includegraphics[scale=0.4]{graphen-kreise.png}
\end{center}

\subsubsection{Bipartite Graphen}
Ein einfacher Graph heisst \textbf{bipartit}, wenn die Knotenmenge in zwei disjunkte Teilmengen aufgeteilt werden kann und wenn alle Kanten nur Verbindungen zwischen den beiden Teilmengen herstellen. Es gibt also keine Kanten zwischen zwei Knoten aus der gleichen Teilmenge. \\
Ein bipartiter Graph heisst \textbf{vollständig}, wenn jeder Knoten aus der einen Teilmenge mit allen Knoten aus der andern Teilmenge verbunden ist. Wir bezeichnen einen vollständigen bipartiten Graph mit ($K_{a,b}$).
\begin{center}
\includegraphics[scale=0.4]{graphen-bipartite.png}
\end{center}

\subsubsection{Hyperwürfel}
Eine etwas spezielle Art eines Graphen ist der Hyperwürfel. Dieser Graph ist wiederum ein einfacher Graph. Seine Knoten haben jedoch ganz bestimmte Namen. Ein Hyperwürfel der Dimension d hat die Knotenmenge, welche aus allen binären Folgen der Länge d besteht. Formal heisst dies: $V= \{ \{0,1\}d \}$. Eine Kante verbindet immer genau dann zwei Knoten, wenn sich deren Binärfolge in nur einer Stelle unterscheiden. Z.B. werden die zwei Knoten mit den Binärfolgen 1011 und 1001 miteinander verbunden. Solche Hyperwürfel werden zum Beispiel in der Codierungstheorie verwendet.

\subsubsection{Planare Graphen}
Planare Graphen sind einfache Graphen, welche so gezeichnet werden können, dass sich keine zwei Kanten überschneiden. 
\begin{description}
	\item[Bäume sind planar.] \hfill \\ Durch ihre spezielle Struktur können alle Bäume so gezeichnet werden, dass sich keine zwei Kanten überschneiden.
	\item[Eulersche Polyederformel]  \hfill \\ Sei G ein planarer, zusammenhängender, einfacher Graph mit n Knoten, m Kanten und f Gebieten. Dann gilt: $n-m+$f$=2$.
	\item[Das Verhältnis von Gebieten zu Kanten] \hfill \\
		$3f \leq 2m$ \\
		Ein Gebiet wird von mindestens drei Kanten begrenzt. Eine Kante begrenzt immer zwei Gebiete. 3f bezeichnet alle Randkanten. Dabei ist aber jede Kante doppelt gezählt.
	\item[Kanten und Regionen in planaren Graphen] \hfill \\
		Für jeden einfachen planaren Graphen $G = (V,E)$ mit $|V| \geq 3$ gilt: \\ $m \leq 3n-6$ und $f \leq 2n-4$
	\item[$K_5$ und $K_{3,3}$ sind nicht planar] \hfill \\
		$K_5$ oder $K_{3,3}$ sind die beiden kleinsten nicht planaren Graphen, was direkt aus dem Satz von Kuratowski folgt. Der Satz von Kuratowski sagt: "\textit{Ein endlicher Graph ist genau dann planar, wenn er keinen Teilgraphen enthält, der durch Unterteilung von $K_5$ oder $K_{3,3}$ entstanden ist. Unterteilung bedeutet hier das beliebig oft wiederholbare (auch nullmalige) Einfügen von neuen Knoten auf Kanten. Mit Teilgraph ist hier ein Graph gemeint, der aus dem ursprünglichen Graphen durch Entfernen von Knoten bzw. Kanten entsteht."} Somit erlaubt der Satz von Kuratowski zu entscheiden, ob ein Graph planar ist oder nicht.	
\end{description}

\subsection{Gerichtete Graphen (Digraphen)}
Im Unterschied zu den allgemeinen Graphen besitzen die Kanten gerichteter Graphen eine Richtung. Das bedeutet, dass eine Kante zwischen zwei Knoten nur in einer Richtung durchlaufen werden darf. \\
Gerichtete Graphen finden ihre Anwendung in ganz verschiedenen Gebieten. In einem Projektplan werden die Aktivitäten mit einer gerichteten Kante verbunden um anzuzeigen, wie der zeitliche Ablauf sein muss. In einer Strassenkarte werden Einbahnstrassen mit einer Richtung versehen.
\begin{description}
	\item[Eingangsgrad] \hfill \\ Der Eingangsgrad (Indegree) eines Knoten entspricht der Anzahl gerichteter Kanten, die in den Knoten hineinführen: \textbf{indeg(v)}
	\item[Ausgangsgrad] \hfill \\ Der Ausgangsgrad (Outdegree) eines Knoten entspricht der Anzahl gerichteten Kanten, die aus dem Knoten hinausführen: \textbf{outdeg(v)}
\end{description}
\begin{center}
	\textbf{Die Summe der Eingangsgrade aller Knoten ist gleich der Summe der Ausgangsgrade aller Knoten:} $\sum indeg(v) = \sum outdeg(v)$
\end{center}

\subsection{Speicherung von Graphen}
Die Art der Speicherung der Graphen kann auf die Effizienz der auszuführenden Algorithmen einen Einfluss haben. Das ist eigentlich nichts Neues, wie Sie schon längst bei anderen Datenstrukturen gesehen haben. Aus diesem Grund ist es wichtig, Graphen speicher- und laufzeiteffizient abzuspeichern.

\subsubsection{Adjazenzmatrix}
Die Adjazenzmatrix ist eine Matrix der Grässe n x n, wobei n die Anzahl der Knoten bezeichnet. Sind zwei Knoten (u \& v)mit einer gerichteten Kante verbunden wird in der u-ten Zeile und der v-ten Spalte eine 1 eingetragen. Sind die beiden Knoten mit mehr als einer Kante verbunden, wird die Anzahl der Kanten eingetragen. Für u und v gilt $1 \leq u \leq n$, $1 \leq v \leq n$. \\
Wenn der Graph gewichtet ist, dann wird das Gewicht der Kante in die Zelle eingetragen. Bei gewichteten Graphen ist es unüblich, dass Mehrfachkanten auftreten. Es kann nicht unterscheiden werden, ob die Kanten gewichtet sind oder ob Mehrfachkanten aufgetreten sind. \\
\begin{center}
\includegraphics[scale=0.6]{graphen-adjazenzmatrix.png} \\
$G=(V,E)$ mit $V=\{1,2,3,4,5\}$ und $E= \{(1,3), (1,3), (3,4), (2,3), (2,5), (5,5)\}$
\end{center}

\subsubsection{Inzidenzmatrix}
Die Inzidenzmatrix ist eine (n x m)-Matrix. Dabei werden nicht nur die Knoten nummeriert, sondern auch die Kanten. Gehört eine Kante e mit Index j zu einem Knoten v, wird in der v-ten Zeile und der j-ten Spalte eine 1 eingetragen. Ansonsten wird eine 0 eingetragen. Für v und j gelten $1 \leq v \leq n$, $1 \leq j \leq m$. \\
Für gerichtete Graphen kann die Darstellung nicht einfach übernommen werden. Mann muss definieren können, ob ein inzidenter Knoten der Ursprung oder das Ziel ist. Man könnte z.B. für Ursprung eine 1 eintragen und für Ziel eine -1. \\
Gewichte der Kanten können in der Inzidenzmatrix berücksichtigt werden indem der Wert des Gewichts in der Matrix eingetragen wird.\\
\begin{center}
\includegraphics[scale=0.6]{graphen-inzidenzmatrix.png} \\
$G=(V,E)$ mit $V=\{1,2,3,4,5\}$ und $E= \{\{1,3\}, \{1,3\}, \{3,4\}, \{2,3\}, \{2,5\}, \{5\}\}$
\end{center}

\subsubsection{Adjazenzlisten}
Wie bei der Adjazenzmatrix werden bei dieser Speicherung die Verbindungen zwischen zwei Knoten in den Vordergrund gestellt. Es wird also gespeichert, welcher Knoten mit welchem anderen Knoten benachbart ist. \\
Die Grundlage der Speicherung ist ein Knoten-Array. Dieses Array hat so viele Felder, wie es Knoten gibt. Jedem Knoten wird eine Position im Array zugeteilt. Im Knoten-Array werden mindestens die Anfangszeiger auf verkettete Listen gespeichert. In diesen Listen sind die Knoten gespeichert, zu welchen eine direkte Verbindung durch eine Kante besteht. Die Kante (u, v) aus dem Graph führt zu einem Eintrag in der Liste an der Stelle u im Array. \\
Diese Speicherung benötigt $\Theta$(n + m) Speicherplatz. Adjazenzlisten unterstützen viele Operationen, z.B. das Verfolgen von gerichteten Kanten in Graphen. Andere Operationen dagegen werden nur schlecht unterstützt, insbesondere das Hinzufügen und Entfernen von Knoten
\begin{center}
\includegraphics[scale=0.3]{graphen-adjazenzlisten.png} \\
$G=(V,E)$ mit $V=\{1, 2, ..., 9\}$ und $E= \{(1,2), (1,3), (1,7), (4,6), (5,4), (6,1), (6,5), (6,6), (7,5), (9,8)\}$
\end{center}

\subsubsection{doppelt verketteten Listen}
Bei dieser Speicherung werden die Knoten und die Kanten als Objekte behandelt. Es wird ihnen also zugestanden, mehr Information als nur den Namen zu enthalten.
Die Basis bildet eine doppelt verkettete Liste, welche die Knotenobjekte enthält. Jedes Knotenobjekt speichert dann eine Liste mit den von ihm ausgehenden Kanten-Objekten. Auch diese Liste ist doppelt verkettet.
Ein Kantenobjekt enthält drei Referenzen. Zwei Referenzen werden für die doppelt verkettete Kantenliste benötigt. Die dritte Referenz zeigt auf den Knoten, auf den die gerichtete Kante zeigt. Zusätzlich können im Kantenobjekt noch weitere Informationen wie z.B. das Gewicht der Kante gespeichert werden.
\begin{center}
\includegraphics[scale=0.4]{graphen-doppelt-verkettete-listen.png} \\
$G=(V,E)$ mit $V=\{1, 2, ..., 9\}$ und $E= \{(1,2), (1,3), (1,7), (4,6), (5,4), (6,1), (6,5), (6,6), (7,5), (9,8)\}$
\end{center}

\subsection{Graphenalgorithmen}
\subsubsection{Topologisches Sortieren}
Eine topologische Sortierung basiert auf einer vergleichenden Relation. In einem gerichteten Graphen besteht durch die Kantenrichtung eine solche vergleichende Relation zwischen je zwei benachbarten Knoten. Die Kantenrichtung kann dabei gelesen werden wie zum Beispiel: \textit{"grösser als"}. In ungerichteten Graphen besteht diese vergleichende Relation nicht und daher kann keine topologische Sortierung erreicht werden. \\
Ein Zyklus oder Kreis ist eine Folge von Kanten bei der Anfangs- und Endpunkt dieselben sind. Eine Schlinge ist der kleinstmögliche Zyklus mit genau einem Knoten. Nicht für alle Digraphen kann eine topologische Sortierung erzeugt werden. Die zentrale Eigenschaft von topologisch sortierbaren Digraphen ist, dass sie keine Zyklen enthalten, also zyklenfrei sind. \\
\textbf{Satz:} \textit{Jeder zyklenfreie Graph hat eine topologische Sortierung.} \\
Die Idee des Algorithmus ist es, mit Knoten zu arbeiten, welche keine eingehenden Kanten haben, d.h. die $indeg(v) = 0$ besitzen. Diese Knoten können nicht zu einem Zyklus gehören, da sie von keinem anderen Knoten erreicht werden können. In einem topologisch sortierbaren Graphen muss es mindestens einen Knoten v mit indeg(v) = 0 geben. Dieser Knoten wird markiert und bildet den Anfang der topologischen Sortierung. Alle markierten Knoten werden konzeptionell der Reihe nach aus dem Graphen entfernt. Dadurch erniedrigt sich der Eingangsgrad anderer Knoten und es gibt wieder einen oder mehrere neue Knoten mit $indeg(v) = 0$. \\
\textbf{Beispiel:}
\begin{center}

\includegraphics[scale=0.4]{graphen-topologisches-sortieren.png} \\
$1 \rightarrow 2 \rightarrow 5 \rightarrow 3 \rightarrow 4 \rightarrow 6$
\end{center}
\lstinputlisting[language=java,caption=TopologicalSort,style=JavaStyle]{TopologicalSort.java}

\subsubsection{Tiefensuche (DFS)}
Die DFS-Strategie ist eine Verallgemeinerung des Preorder-Durchlaufprinzips bei Binärbäumen. Das Prinzip ist das folgende:
\begin{itemize}
	\item Kanten werden ausgehend von dem zuletzt entdeckten Knoten v, der mit noch unerforschten Kanten inzident ist, erforscht.
	\item Erreicht man von v aus einen noch nicht erforschten Knoten w, so verfährt man mit w genauso wie mit v.
	\item Wenn alle mit w inzidenten Kanten erforscht sind, erfolgt ein Backtracking zu v.
\end{itemize}
Eine Methode ist es drei Arten von Knoten zu haben. Am Anfang ist jeder Knoten weiss. Das bedeutet, dass er noch nicht entdeckt worden ist. Sobald ein Knoten entdeckt worden ist, wird er grau. Wenn ein Knoten komplett abgearbeitet ist, wird er schwarz gefärbt. Dies ist der Fall, wenn er das Backtracking zum Vorgängerknoten einleitet. Des Weiteren wird für jeden Knoten noch abgespeichert, wer sein Vorgänger ist. Der Vorgänger wird in einem Array $\alpha$ gespeichert. Durch dieses Verfahren werden alle Zusammenhangskomponenten gefunden. Jeder Knoten und jede Kante werden einmal besucht. Am Ende enthält $\alpha$ die Informationen eines Spannbaums für den Graphen, falls dieser zusammenhängend ist.
\begin{center}
\includegraphics[scale=0.3]{graphen-tiefensuche.png} 
\end{center}
\lstinputlisting[language=java,caption=Tiefensuche,style=JavaStyle]{Tiefensuche.java}

\subsubsection{Breitensuche (BFS)}
Der Algorithmus für die Breitensuche lautet wie folgt:
\begin{itemize}
	\item[1.] Für einen Knoten werden die noch nicht besuchten Nachbarknoten gesucht.
	\item[2.] Jeder Nachbarknoten wird ans Ende einer Warteschlange eingefügt.
	\item[3.] Solange die Warteschlange nicht leer ist, wähle den nächsten Knoten und beginne wieder bei 1.
\end{itemize}
\lstinputlisting[language=java,caption=Breitensuche,style=JavaStyle]{Breitensuche.java}


\subsubsection{Kürzeste Pfade mit Dijkstra}
Der Algorithmus von Dijkstra arbeitet mit einer \textit{Wellenfront-Strategie}. Der Algorithmus von Dijkstra setzt nicht negative Kantengewichte voraus. Für alle Knoten hinter der Front ist der endgültige Distanzwert bereits ermittelt worden. Wir nennen diese Knoten permanent und speichern sie ab. Für diese Knoten v gilt also: $dist(s, v) = d[v]$. Die Knoten vor der Front sind noch nicht bearbeitet worden. Für alle Knoten auf der Front ist die Berechnung in Gange. Diese Knoten werden in einer Prioritätswarteschlange PQ gespeichert. Die Prioritäten entsprechen den momentanen Abständen zum Startknoten. \\
Anfangszustand: Am Anfang ist die Menge der permanenten Knoten leer. Die Menge der Knoten auf der Front enthält nur den Startknoten s.
\begin{itemize}
	\item Nimm einen Knoten u aus PQ, welcher den kleinsten Abstand zu s hat.
	\item Für alle Nachbarknoten v von u überprüfe die Distanz. Wenn nötig wird diese Distanz aktualisiert. Ist der Nachbarknoten v schon in PQ, wird seine Priorität dort aktualisiert. Ist er noch nicht in dieser Menge, wird er mit dem aktuellen Wert der Distanz in diese Menge eingefügt.
	\item Nimm den Knoten u in die Menge der permanenten Knoten auf.
\end{itemize}
\lstinputlisting[language=java,caption=Dijkstra,style=JavaStyle]{Dijkstra.java}


\subsubsection{Kürzeste Pfade mit Bellman und Ford}
Der Algorithmus von Bellman und Ford, der hier erklärt wird, kann auch mit negativen Gewichten umgehen (wenn der Graph gerichtet ist). Wenn negative Gewichte zugelassen sind, tritt ein grundsätzliches Problem auf: es kann ein Kreis negativer Länge von s aus erreichbar sein und damit $dist(s, v)= - \infty $ für alle Knoten v gelten, die von s aus erreichbar sind. Denn dieser Kreis kann unendlich viele Male durchlaufen werden und vermindert den Wert des Pfades bei jedem Durchlaufen.
\begin{itemize}
	\item Es gibt n Phasen, wobei in der ersten Phase initialisiert wird.
	\item In jeder weiteren Phase wird jede Kante mit test(u, v) überprüft und d[v] aktualisiert.
	\item Am Ende enthält das Array d[v] für alle Knoten v die Distanz zwischen s und v.
\end{itemize}
Es ist zentral, dass eine Kantenreihenfolge festgelegt wird, in der alle Kanten des Graphen besucht werden. Obwohl der Algorithmus für alle möglichen Kantenreihenfolgen funktioniert, hat die Wahl Einfluss darauf, wie früh die kürzesten Distanzen entdeckt werden.
\lstinputlisting[language=java,caption=BellmanFord,style=JavaStyle]{BellmanFord.java}

\pagebreak
\subsection{Spannbäume}
Spannbäume sind Bäume die aus Kanten eines Graphen bestehen. Ein Baum mit n Knoten hat genau n-1 Kanten. Für einen Spannbaum werden also n-1 Kanten aus der Menge der Kanten ausgesucht, so dass ein zusammenhängender Graph entsteht. In diesem Graphen gibt es zwischen zwei Knoten genau einen Weg. \\
Im Code von BFS und DFS ist das Berechnen eines Spannbaumes schon \textit{eingebaut}. Speichert jeder Knoten den adjazenten Knoten, von dem er entdeckt wurde, dann entspricht dies dem Speichern des Vaters im Spannbaum.
\begin{center}
\includegraphics[scale=0.3]{graphen-spannbaum.png} 
\end{center}

\subsubsection{Definitionen}
\begin{description}
	\item[Spannbaum] \hfill \\
		Ein Spannbaum ST (Spanning Tree) eines Graphen $G = (V, E)$ besteht aus $n-1$ Kanten der Menge E. Diese Kanten bilden einen zusammenhängenden Graphen, der alle Knoten aus V enthält.
	\item[Minimaler Spannbaum] \hfill \\
		Ein minimaler Spannbaum MST (Minimum Spanning Tree) ist ein Spanbaum, bei dem die Summe der Kantengewichte minimal ist.
\end{description}

\subsubsection{Algorithmus von Prim}
Der Algorithmus von Prim, auch Prim-Dijkstra-Algorithmus genannt, funktioniert analog zum Dijkstra-Algorithmus. Der einzige Unterschied liegt darin, dass der Abstand zum Spannbaum und nicht der Abstand zum Startknoten als Priorität verwendet wird. \\
Der Abstand eines Knoten zum Spannbaum ist gleich dem kleinsten Gewicht einer Kante, die den Knoten mit einem Knoten des Spannbaums verbindet.
\begin{center}
\includegraphics[scale=0.3]{graphen-primalg.png} 
\end{center}
Im Beispiel hat der graue Knoten vier inzidente Kanten, die ihn mit Knoten aus dem bisherigen Spannbaum verbinden. Die Kante mit dem geringsten Gewicht hat das Gewicht $(e) = 1$. Somit hat der graue Knoten den Abstand 1 zum Spannbaum. \\
Abstand von v zum minimalen Spannbaum MST: \\
$dist(v, MST) = min \{ w(e) | e = \{ v, u \} \in E$ und $v, u \in V\}$ \\
Ist der Knoten v zu keinem Knoten des Spannbaums adjazent, ist die Distanz unendlich.
\begin{description}
	\item[Start] Als Ausgangspunkt wird ein beliebiger Knoten genommen. Dieser ist zu Beginn der einzige Knoten im Spannbaum. Der Spannbaum enthält noch keine Kante.
	\item[Wachsen] Es wird der Knoten gesucht, der den kleinsten Abstand vom Spannbaum hat. Dieser Knoten darf aber nicht schon im Spannbaum enthalten sein. \\
	 Der Knoten wird dann über die minimale Kante mit dem Spannbaum verbunden und in die Menge der Knoten des Spannbaums aufgenommen.
	\item[Ende] Wenn alle Knoten im Spannbaum enthalten sind, dann ist die Berechnung zu Ende.
\end{description}

\subsubsection{Beispiel des Prim Algorithmus}
\begin{floatingfigure}[r]{5cm}
\includegraphics[scale=0.4]{graphen-prim-bsp.png}
\end{floatingfigure} Gegeben ist ein Graph mit nebenstehender Adjazenzmatrix. Die Werte in den Feldern geben die Kantengewichte an. In diesem Beispiel wird ein Spannbaum ausgehend vom Knoten s berechnet. Das Bild zeigt den momentanen minimalen Spannbaum. Der nächste Knoten, die Queue und die Menge der Knoten werden in der mittleren Spalte angegeben. Rechts werden die Abstände der Knoten angegeben. \\
\begin{center}
\includegraphics[scale=0.7]{graphen-prim-schritte.png} 
\end{center}

\pagebreak
\section{Spieltheorie}
\subsection{Minimax-Algorithmus}
Der Minimax-Algorithmus ist ein Algorithmus zur Ermittlung der optimalen Spielstrategie für endliche Zwei-Personen-Nullsummenspiele mit perfekter Information. Zu diesen Spielen gehören insbesondere Brettspiele wie Schach, Go, Reversi, Dame, Mühle und Vier gewinnt, bei denen beide Spieler stets die gesamte Historie der Partie kennen. Auch für Spiele mit Zufallseinfluss wie Backgammon lässt sich der Minimax-Algorithmus auf Grundlage von Erwartungswerten erweitern. In der Regel, aber nicht ausschließlich, wird der Minimax-Algorithmus auf Spiele mit abwechselndem Zugrecht angewandt.
\subsubsection{Beschreibung}
\begin{floatingfigure}[r]{7cm}
\includegraphics[scale=0.25]{minmax.png} 
\end{floatingfigure} Die Kreise stellen die Züge der Spieler im Algorithmus dar (Maximierung), die Quadrate die Züge der Gegner (Minimierung). Die Werte in den Kreisen und Quadraten stellen den Wert $\alpha$ des Minimax-Algorithmus dar. Die roten Pfeile repräsentieren den gewählten Zug, die Nummern links die Baumtiefe und die blauen Pfeile den gewählten Zug. \\
Die Knoten der Ebenen 0 und 2 entsprechen Spielsituationen, in denen Spieler A am Zug ist. Hier wird jeweils die Bewertungsfunktion der untergeordneten Knoten maximiert, d. h. der für Spieler A günstige Zug ausgewählt und dessen Wert dem Elternknoten zugewiesen. \\
Die Knoten der Ebenen 1 und 3 entsprechen Spielsituationen, in denen Spieler B am Zug ist. Hier wird jeweils die Bewertungsfunktion der untergeordneten Knoten minimiert, d. h. der für Spieler B günstigste Zug ausgewählt und dessen Wert dem Elternknoten zugewiesen.\\
Der Algorithmus beginnt unten bei den Blättern und geht dann nach oben bis zur Wurzel. In Ebene 3 wählt der Algorithmus den kleinsten Wert der Kindknoten und weist diesen dem Elternknoten zu (es wird minimiert). In Ebene 2 wird dann der jeweils größte Kindknoten dem Elternknoten zugewiesen (es wird maximiert). Dies wird abwechselnd so lange durchgeführt bis die Wurzel erreicht ist. Der Wurzel wird der Wert des größten Kindknoten zugewiesen. Dabei handelt es sich dann um den Zug der gespielt werden soll. \\

\subsubsection{Implementierung}
\begin{lstlisting}[language=Java, caption=Auszug Main, style=JavaStyle]
 gespeicherterZug = NULL;
 int gewuenschteTiefe = 4;
 int bewertung = max(+1, gewuenschteTiefe);
 if (gespeicherterZug == NULL)
    es gab keine weiteren Zuege mehr;
 else
    gespeicherterZug ausführen;
\end{lstlisting}
\begin{lstlisting}[language=Java, caption=Funktionen, style=JavaStyle]
 int max(int spieler, int tiefe) {
    if (tiefe == 0 or keineZuegeMehr(spieler)) return bewerten();
    int maxWert = -unendlich;
    generiereMoeglicheZuege(spieler);
    while (noch Zug da) {
       fuehreNaechstenZugAus();
       int wert = min(-spieler, tiefe-1);
       macheZugRueckgaengig();
       if (wert > maxWert) {
          maxWert = wert;
          if (tiefe == anfangstiefe) gespeicherterZug = Zug;
       }
    }
    return maxWert;
 }
int min(int spieler, int tiefe) {
    if (tiefe == 0 or keineZuegeMehr(spieler))
       return bewerten();
    int minWert = unendlich;
    generiereMoeglicheZuege(spieler);
    while (noch Zug da) {
       fuehreNaechstenZugAus();
       int wert = max(-spieler, tiefe-1);
       macheZugRueckgaengig();
       if (wert < minWert) {
          minWert = wert;
       }
    }
    return minWert;
 }
\end{lstlisting}

\pagebreak
\subsection{Alpha-Beta-Suche}
Die Alpha-Beta-Suche, auch Alpha-Beta-Cut oder Alpha-Beta-Pruning genannt, ist eine optimierte Variante des Minimax-Suchverfahrens, also eines Algorithmus zur Bestimmung eines optimalen Zuges bei Spielen mit zwei gegnerischen Parteien. Während der Suche werden zwei Werte Alpha und Beta aktualisiert, die angeben, welches Ergebnis die Spieler bei optimaler Spielweise erzielen können. Mit Hilfe dieser Werte kann entschieden werden, welche Teile des Suchbaumes nicht untersucht werden müssen, weil sie das Ergebnis der Problemlösung nicht beeinflussen können. \\
Die einfache (nicht optimierte) Alpha-Beta-Suche liefert exakt dasselbe Ergebnis wie die Minimax-Suche.
\subsubsection{Beschreibung}
Der Minimax-Algorithmus analysiert den vollständigen Suchbaum. Dabei werden aber auch Knoten betrachtet, die in das Ergebnis (die Wahl des Zweiges an der Wurzel) nicht einfließen. Die Alpha-Beta-Suche versucht, möglichst viele dieser Knoten zu ignorieren. \\
Ein anschauliches Beispiel für die Funktionsweise ist ein Zweipersonenspiel, bei dem der erste Spieler eine von mehreren Taschen auswählt und von seinem Gegenspieler den Gegenstand mit geringstem Wert aus dieser Tasche erhält. \\
Der Minimax-Algorithmus durchsucht für die Auswahl alle Taschen vollständig und benötigt somit viel Zeit. Die Alpha-Beta-Suche hingegen durchsucht zunächst nur die erste Tasche vollständig nach dem Gegenstand mit minimalem Wert. In allen weiteren Taschen wird nur solange gesucht, bis der Wert eines Gegenstands dieses Minimum unterschreitet. Ist dies der Fall, wird die Suche in dieser Tasche abgebrochen und die nächste Tasche untersucht. Andernfalls ist diese Tasche eine bessere Wahl für den ersten Spieler und ihr minimaler Wert dient für die weitere Suche als neue Grenze. \\
Ähnliche Situationen sind jedem Schachspieler vertraut, der gerade einen konkreten Zug darauf prüft, ob er ihm vorteilhaft erscheint. Findet er bei seiner Analyse des Zuges eine für sich selbst ungünstige Erwiderung des Gegners, dann wird er diesen Zug als \textit{widerlegt} ansehen und verwerfen. Es wäre völlig sinnlos, noch weitere Erwiderungen des Gegners zu untersuchen um festzustellen, ob der Gegner noch effektivere Widerlegungen besitzt und wie schlecht der geplante Zug tatsächlich für den Spieler ist.

\subsubsection{Der Algorithmus}
Die Alpha-Beta-Suche arbeitet prinzipiell genauso wie obige informelle Beschreibung. Die Idee ist, dass zwei Werte (Alpha und Beta) weitergereicht werden, die das Worst-Case-Szenario der Spieler beschreiben. Der Alpha-Wert ist das Ergebnis, das Spieler A mindestens erreichen wird, der Beta-Wert ist das Ergebnis, das Spieler B höchstens erreichen wird (Hier ist zu beachten, dass es für Spieler B darum geht, ein möglichst niedriges Ergebnis zu erhalten, da er ja \textit{minimierend} spielt!) \\
Besitzt ein maximierender Knoten (von Spieler A) einen Zug, dessen Rückgabe den Beta-Wert überschreitet, wird die Suche in diesem Knoten abgebrochen (Beta-Cutoff, denn Spieler B würde A diese Variante erst gar nicht anbieten, weil sie sein bisheriges Höchst-Zugeständnis überschreiten würde). Liefert der Zug stattdessen ein Ergebnis, das den momentanen Alpha-Wert übersteigt, wird dieser entsprechend nach oben angehoben. \\
Analoges gilt für die minimierenden Knoten, wobei bei Werten kleiner als Alpha abgebrochen wird (Alpha-Cutoff) und der Beta-Wert nach unten angepasst wird. \\
\begin{center}
\includegraphics[scale=0.6]{alpha_beta.png} 
\end{center}
Obige Abbildung zeigt einen Beispielbaum mit 18 Blättern, von denen nur 12 ausgewertet werden. Die drei umrandeten Werte eines inneren Knotens beschreiben den Alpha-Wert, den Rückgabewert und den Beta-Wert.
Der Suchalgorithmus verwendet ein sogenanntes Alpha-Beta-Fenster, dessen untere Grenze der Alpha-Wert und dessen obere Grenze der Beta-Wert darstellt. Dieses Fenster wird zu den Kindknoten weitergegeben, wobei in der Wurzel mit dem maximalen Fenster [-inf, inf] begonnen wird. Die Blätter 1, 2 und 3 werden von einem maximierenden Knoten ausgewertet und der beste Wert 10 wird dem minimierenden Vaterknoten übergeben. Dieser passt den Beta-Wert an (signalisiert durch die orange Linie links unten) und übergibt das neue Fenster [-inf, 10] dem nächsten maximierenden Kindknoten, der die Blätter 4, 5 und 6 besitzt. Der Rückgabewert 12 von Blatt 5 ist aber so gut, dass er den Beta-Wert 10 überschreitet. Somit muss Blatt 6 nicht mehr betrachtet werden, weil das Ergebnis 12 dieses Teilbaumes besser ist, als das des linken Teilbaumes, und deshalb vom minimierenden Spieler nie gewählt werden würde. \\
Ähnlich verhält es sich beim minimierenden Knoten mit dem 3-Alpha-Cutoff. Obwohl dieser Teilbaum erst teilweise ausgewertet wurde, ist klar, dass der maximierende Wurzelknoten diese Variante niemals wählen würde, weil der minimierende Knoten ein Ergebnis von höchstens 3 erzwingen könnte, während aus dem mittleren Teilbaum das Ergebnis 12 sichergestellt ist.

\subsubsection{Implementierung}
\begin{lstlisting}[language=Java, caption=Auszug Main, style=JavaStyle]
 gespeicherterZug = NULL;
 int gewuenschteTiefe = 4;
 int bewertung = max(+1, gewuenschteTiefe, -unendlich, +unendlich);
 if (gespeicherterZug == NULL)
    es gab keine weiteren Zuege mehr;
 else
    gespeicherterZug ausführen;
\end{lstlisting}
\begin{lstlisting}[language=Java, caption=Funktionen, style=JavaStyle]
 int max(int spieler, int tiefe, int alpha, int beta) {
    if (tiefe == 0 or keineZuegeMehr(spieler)) return bewerten();
    int maxWert = alpha;
    generiereMoeglicheZuege(spieler);
    while (noch Zug da) {
       fuehreNaechstenZugAus();
       int wert = min(-spieler, tiefe-1, maxWert, beta);
       macheZugRueckgaengig();
       if (wert > maxWert) {
          maxWert = wert;
          if (maxWert >= beta) break;
          if (tiefe == anfangstiefe) gespeicherterZug = Zug;
       }
    }
    return maxWert;
 }
 int min(int spieler, int tiefe, int alpha, int beta) {
    if (tiefe == 0 or keineZuegeMehr(spieler)) return bewerten();
    int minWert = beta;
    generiereMoeglicheZuege(spieler);
    while (noch Zug da) {
       fuehreNaechstenZugAus();
       int wert = max(-spieler, tiefe-1, alpha, minWert);
       macheZugRueckgaengig();
       if (wert < minWert) {
          minWert = wert;
          if (minWert <= alpha) break;
       }
    }
    return minWert;
 }
\end{lstlisting}
\end{document}